# 4D Association Graph for Realtime Multi-person Motion Capture Using Multiple Video Cameras
Note: As a python variable name cannot start with a number, we refer to this method as `FourDAG` in the following text and code.

  - [Introduction](#introduction)
  - [Prepare limb information and datasets](#prepare-limb-information-and-datasets)
  - [Results](#results)
    - [Campus](#campus)
    - [Shelf](#shelf)
    - [FourDAG](#fourdag-1)

## Introduction

We provide the config files for FourDAG: [4D Association Graph for Realtime Multi-person Motion Capture Using Multiple Video Cameras](https://arxiv.org/abs/2002.12625).


[Official Implementation](https://github.com/zhangyux15/4d_association)

```BibTeX
@inproceedings{Zhang20204DAG,
  title={4D Association Graph for Realtime Multi-Person Motion Capture Using Multiple Video Cameras},
  author={Yuxiang Zhang and Liang An and Tao Yu and Xiu Li and Kun Li and Yebin Liu},
  journal={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2020},
  pages={1321-1330}
}
```
## Prepare limb information and datasets

- **Prepare limb information**:

```
sh scripts/download_weight.sh
```
You could find perception models in `weight` file.

- **Prepare the datasets**:

You could download Shelf, Campus or FourDAG datasets, and convert original dataset to our unified meta-data. Considering that it takes long to run a converter, we have done it for you. Please download compressed zip file for converted meta-data from [here](../../docs/en/dataset_preparation.md), and place meta-data under `ROOT/xrmocap_data/DATASET`.

The final file structure would be like:

```text
xrmocap
├── xrmocap
├── docs
├── tools
├── configs
├── weight
|   └── limb_info.json
└── xrmocap_data
    ├── CampusSeq1
    ├── Shelf
    |   ├── Camera0
    |   ├── ...
    |   ├── Camera4
    |   └── xrmocap_meta_testset
    └── FourDAG
        ├── seq2
        ├── seq4
        ├── seq5
        ├── xrmocap_meta_seq2
        ├── xrmocap_meta_seq4
        └── xrmocap_meta_seq5
```
You can download just one dataset of Shelf, Campus and FourDAG.

## Results

We evaluate FourDAG on 3 benchmarks, report the Percentage of Correct Parts (PCP) on Shelf/Campus/FourDAG datasets.

You can find the recommended configs in `configs/foudage/*/eval_keypoints3d.py`.


### Campus

The 2D keypoints and pafs data we use is generated by openpose, and you can download it from [here](/docs/en/dataset_preparation.md#download-converted-meta-data).

| Config | Actor 0 | Actor 1 | Actor 2 | Average | Download |
|:------:|:-------:|:--------:|:--------:|:--------:|:--------:|
| [eval_keypoints3d.py](./campus_config/eval_keypoints3d.py) | 64.26 | 90.64 | 86.27 | 80.39 | [log](https://openxrlab-share-mainland.oss-cn-hangzhou.aliyuncs.com/xrmocap/logs/FourDAG/campus.zip) |


### Shelf

The 2D keypoints and pafs data we use is generated by fasterrcnn, and you can download it from [here](/docs/en/dataset_preparation.md#download-converted-meta-data).

| Config | Actor 0 | Actor 1 | Actor 2 | Average | Download |
|:------:|:-------:|:--------:|:--------:|:--------:|:--------:|
| [eval_keypoints3d.py](./shelf_config/eval_keypoints3d.py) | 99.61 | 96.76 | 98.20 | 98.19 | [log](https://openxrlab-share-mainland.oss-cn-hangzhou.aliyuncs.com/xrmocap/logs/FourDAG/shelf.zip) |


### FourDAG

The 2D keypoints and pafs data we use is generated by mmpose, and you can download it from [here](/docs/en/dataset_preparation.md#download-converted-meta-data).

- **seq2**

| Config | Actor 0 | Actor 1 | Average | PCK@200mm | Download |
|:-------:|:--------:|:--------:|:--------:|:--------:|:--------:|
| [eval_keypoints3d.py](./fourdag_config/eval_keypoints3d_seq2.py) | 92.18 | 87.35 | 89.77 | 83.10 | [log](https://openxrlab-share-mainland.oss-cn-hangzhou.aliyuncs.com/xrmocap/logs/FourDAG/fourdag.zip) |

- **seq4**

| Config | Actor 0 | Actor 1 | Actor 1 | Average | PCK@200mm | Download |
|:-------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|
| [eval_keypoints3d.py](./fourdag_config/eval_keypoints3d_seq4.py) | 91.85 | 86.48 | 92.92 | 90.42 | 81.29 |[log](https://openxrlab-share-mainland.oss-cn-hangzhou.aliyuncs.com/xrmocap/logs/FourDAG/fourdag.zip) |
